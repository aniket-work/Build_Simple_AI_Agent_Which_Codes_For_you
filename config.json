{
    "llm_config": [
        {
            "model": "llama3.1",
            "base_url": "http://localhost:11434/v1",
            "api_key": "ollama",
            "seed": null
        }
    ],
    "seed": null
}